{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import trange\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.stats.qmc import Halton\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from botorch.models import SingleTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.acquisition import UpperConfidenceBound, ExpectedImprovement\n",
    "from botorch.test_functions import Hartmann\n",
    "\n",
    "from botorch.models.transforms import Standardize\n",
    "from botorch.models.transforms.input import Normalize\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "SEEDS = np.loadtxt('seeds.txt', delimiter=',', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed=42):\n",
    "    \"\"\"set all library random seeds\"\"\"\n",
    "    seed = int(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "def random_sample(num_points, dims, seed=42):\n",
    "    \"\"\"generate random points in the domain\"\"\"\n",
    "    set_seeds(seed)\n",
    "    return torch.rand(num_points, dims, dtype=torch.double)\n",
    "\n",
    "def execute_campaign(n_campaigns=10, campaign_budget=30, n_init_samples=5, raw_samples=250, num_restarts=20):\n",
    "\n",
    "    data = np.zeros((n_campaigns, campaign_budget))\n",
    "    campaign_budget = campaign_budget - n_init_samples\n",
    "\n",
    "    HART = Hartmann(dim=6, bounds=[(0,1)]*6 ,negate=True) # objective function - call with X, returns y values (like an experiment)\n",
    "    X_ = random_sample(n_init_samples, 6) #  6 is num of dims \n",
    "    y_ = torch.tensor([HART(x) for x in X_])[:,None]\n",
    "\n",
    "    for campaign in trange(n_campaigns, desc=f'Running RS={raw_samples}, NR={num_restarts}'):\n",
    "        set_seeds(SEEDS[campaign])\n",
    "        X = X_.clone()\n",
    "        y = y_.clone()\n",
    "\n",
    "        for trial in range(campaign_budget):\n",
    "\n",
    "            gp = SingleTaskGP(\n",
    "                train_X = X,\n",
    "                train_Y = y,\n",
    "                input_transform=Normalize(d=X.shape[-1]), # normalize X values [0,1]\n",
    "                outcome_transform=Standardize(m=y.shape[-1]) # standardize y values [mean of 0, std of 1]\n",
    "            )\n",
    "\n",
    "            # fit the model by maximizing the log marginal likelihood\n",
    "            mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "            mll = fit_gpytorch_model(mll)\n",
    "\n",
    "            bounds = torch.tensor([[0.0]*X.shape[-1], [1.0]*X.shape[-1]])\n",
    "\n",
    "            X_new, acq_value = optimize_acqf( # acq value is whatever came out of acqf (y value of acqf)\n",
    "                acq_function= UpperConfidenceBound(gp, beta=2),  # beta= 2 std from mean\n",
    "                bounds=bounds, # where to search for X values\n",
    "                q=1, # how many new points to generate # one new experiment to do\n",
    "                num_restarts = num_restarts, # how many times to restart the optimizer\n",
    "                raw_samples = raw_samples # how many initial points to sample acqf space from\n",
    "            )\n",
    "\n",
    "            X = torch.cat([X, X_new])\n",
    "            y = torch.cat([y, HART(X=X_new)[:,None]]) # new exp observation is HART(X_new)\n",
    "\n",
    "        data[campaign,:] = y.flatten()\n",
    "    \n",
    "    return data\n",
    "\n",
    "def generate_points(vis=False):\n",
    "    points = Halton(2, optimization='lloyd', seed=3).random(150)\n",
    "    points = points * np.array([200, 2048]) + 1\n",
    "    points = points.astype(np.int32)\n",
    "    return points\n",
    "    if vis:\n",
    "        plt.scatter(points[:,0], points[:,1])\n",
    "        plt.xlabel('num_restarts')\n",
    "        plt.ylabel('raw_samples')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running RS=314, NR=100: 100%|██████████| 3/3 [00:15<00:00,  5.10s/it]\n",
      "Running RS=966, NR=9: 100%|██████████| 3/3 [00:04<00:00,  1.63s/it]\n"
     ]
    }
   ],
   "source": [
    "sampling_points = generate_points(vis=False)\n",
    "\n",
    "for i, param in enumerate(sampling_points):\n",
    "    num_restarts, raw_samples = param\n",
    "    num_restarts = int(num_restarts)\n",
    "    raw_samples = int(raw_samples)\n",
    "    ensemble = execute_campaign(\n",
    "        n_campaigns=3,\n",
    "        campaign_budget=15,\n",
    "        n_init_samples=5,\n",
    "        num_restarts=num_restarts, \n",
    "        raw_samples=raw_samples\n",
    "    )\n",
    "    # save ensemble to csv\n",
    "    np.savetxt(f'ensemble_res/ensemble_{num_restarts}_{raw_samples}.csv', ensemble, delimiter=',')\n",
    "    if i ==1:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MatInformatics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
